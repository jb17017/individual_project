{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "diss_toxicity_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03b8e22bb7864a2f93d5608c117f0f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d490d60267f542c7bc603402ae9acd36",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_16dc50f1981a4ce0ae577795a0e6b17e",
              "IPY_MODEL_68cacfdc20814366ad2c3393909c99c9"
            ]
          }
        },
        "d490d60267f542c7bc603402ae9acd36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16dc50f1981a4ce0ae577795a0e6b17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f3129240e2054d87abf6d8a9514812aa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8401c6a4df684b8a9f4bb6d321fa858a"
          }
        },
        "68cacfdc20814366ad2c3393909c99c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a3842e2d829418c8fc284048f6dc760",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 95.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87a575a177744b6c8e5b5d872723b78a"
          }
        },
        "f3129240e2054d87abf6d8a9514812aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8401c6a4df684b8a9f4bb6d321fa858a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a3842e2d829418c8fc284048f6dc760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87a575a177744b6c8e5b5d872723b78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2bc03b7f2574d3abfe3abe3ee3e4ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9a96d9e68bd44e7a864c114368e4675",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ec124e81c974d47a4a39f02ced8598c",
              "IPY_MODEL_e65b7c22d26d4f19a38fc26a2fc7e161"
            ]
          }
        },
        "f9a96d9e68bd44e7a864c114368e4675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ec124e81c974d47a4a39f02ced8598c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79b477aaf68644fe80a55416ec8a530d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4399770293fd43e8b44077729a0f719a"
          }
        },
        "e65b7c22d26d4f19a38fc26a2fc7e161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd3c069f723249e0aaf74ce8ba9ffc1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 47.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_558029770a644efe8a09722696a1290e"
          }
        },
        "79b477aaf68644fe80a55416ec8a530d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4399770293fd43e8b44077729a0f719a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd3c069f723249e0aaf74ce8ba9ffc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "558029770a644efe8a09722696a1290e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bae9f79905d4bf4b52edbac9f37dd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad540df0bac44d879ee767dfa509c7d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a14133cb91b41c998c184f1bbf6b211",
              "IPY_MODEL_72a494b5ecaa4a1a901dd90be536ff12"
            ]
          }
        },
        "ad540df0bac44d879ee767dfa509c7d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a14133cb91b41c998c184f1bbf6b211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e6bdeddc0f04f58b3bf47b77174930b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be0db0e9fa804baea36bbec4e5d6534b"
          }
        },
        "72a494b5ecaa4a1a901dd90be536ff12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85ff093064a24aa380b385c892a73900",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad862c91a72a4d158400644697673d0e"
          }
        },
        "5e6bdeddc0f04f58b3bf47b77174930b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be0db0e9fa804baea36bbec4e5d6534b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85ff093064a24aa380b385c892a73900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad862c91a72a4d158400644697673d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c705c5c0bd04ce696fd201f12dbb80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb8816bdddd448ee90423359904da048",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5a2d70ee8491428c84793a806b215c21",
              "IPY_MODEL_7e04eb259b154680b4edc0500ce04860"
            ]
          }
        },
        "bb8816bdddd448ee90423359904da048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a2d70ee8491428c84793a806b215c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8aafc3f2715441999ef9e409f6a0fc93",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b739c85fa00c427fad743d8589d6f843"
          }
        },
        "7e04eb259b154680b4edc0500ce04860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a70c415b215d4925b6cf2f61d0412db5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 988B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23e357215ff14762804abd40c8ec6489"
          }
        },
        "8aafc3f2715441999ef9e409f6a0fc93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b739c85fa00c427fad743d8589d6f843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a70c415b215d4925b6cf2f61d0412db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23e357215ff14762804abd40c8ec6489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ddea46da9524084a2a050adf3e3cc5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_74b05bdff49f42718204628db5ba6389",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_576bb3b079ab48e9aa3d8462ad6e6e2b",
              "IPY_MODEL_da8d5a7221c541b3a70af04d87fad45a"
            ]
          }
        },
        "74b05bdff49f42718204628db5ba6389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "576bb3b079ab48e9aa3d8462ad6e6e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3af0f09f88e4f4a94e319cd41bd4f9d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c26c8abcb54479bbe123fcf9186ed00"
          }
        },
        "da8d5a7221c541b3a70af04d87fad45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e347f235d91a452c9ace2ebf914c915a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [08:17&lt;00:00, 886kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_382ac2f9018c4c2ca48c7c38b1b082bc"
          }
        },
        "b3af0f09f88e4f4a94e319cd41bd4f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c26c8abcb54479bbe123fcf9186ed00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e347f235d91a452c9ace2ebf914c915a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "382ac2f9018c4c2ca48c7c38b1b082bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRE4R_1ZqMhY"
      },
      "source": [
        "Need to go to the runtime tab, then change runtime and click the drop down menu on hardware accelerator and select GPU. With Google Colab Pro also change Runtime shape to High-RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVToy-m7po45",
        "outputId": "bb416fc1-f0ae-4593-ff3e-f48b2b80d1fb"
      },
      "source": [
        "# Install libraries needed using pip\n",
        "!pip install transformers\n",
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 46.0MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.1\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=0a05248ebe525cb7c3ce12ac9b7453ee257fc38a2ef12c8e98a6fa81dfcc0d4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnVFfcquo5OE",
        "outputId": "d1b4da74-bc51-4981-ab53-c805a2c641e4"
      },
      "source": [
        "# Import libraries needed\n",
        "import torch\n",
        "import wget\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import precision_score, recall_score, matthews_corrcoef, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import itertools\n",
        "print(\"All libraries imported.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All libraries imported.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t01DmGhCp-6U",
        "outputId": "a649ce3a-abf9-4398-ba0c-f7b48799a197"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There is %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There is 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmHf6rLRqzct",
        "outputId": "13ba8951-cae0-4c75-92ec-d6eb92f86977"
      },
      "source": [
        "#This code block downloads all of the needed project data sets.\n",
        "print('Downloading dataset')\n",
        "# The URL for the dataset zip file.\n",
        "#The Data sets are installed from a .zip file in a GitHub repo\n",
        "url = 'https://github.com/jb17017/individual_project/blob/main/Datasets.zip?raw=true'\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./Datasets.zip'):\n",
        "    wget.download(url, './Datasets.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_rNhGl_rCP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b35eeabc-f6c3-4d32-c0b0-14e85a370360"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./Datasets/'):\n",
        "    !unzip Datasets.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Datasets.zip\n",
            "  inflating: Datasets/dota2_combined_player_and_none_combined_training_set.csv  \n",
            "  inflating: Datasets/dota2_olid_combined_training_set.csv  \n",
            "  inflating: Datasets/dota2_test_set.csv  \n",
            "  inflating: Datasets/dota2_training_set.csv  \n",
            "  inflating: Datasets/labels-levela.csv  \n",
            "  inflating: Datasets/olid-training-v1.0.tsv  \n",
            "  inflating: Datasets/testset-levela.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m1d9C7FPY4a"
      },
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "\n",
        "def train_data_unpacker():\n",
        "  #Dota 2 training set \n",
        "  dota_training_set = pd.read_csv(\"./Datasets/dota2_training_set.csv\", header=None, names=['index', 'local match index', 'text','label'])\n",
        "\n",
        "  dota_train_sentences = dota_training_set.text.values\n",
        "  dota_train_labels = dota_training_set.label.values\n",
        "\n",
        "  #Converts the string labels to numbers so they can be used in the binary classifier\n",
        "  dota_train_labels_num = label_to_number(dota_train_labels)\n",
        "\n",
        "  print('Number of dota 2 training sentences: {:,}\\n'.format(dota_training_set.shape[0]))\n",
        "\n",
        "  #Dota 2 training set with player messages combined\n",
        "  dota_training_player_combined_set = pd.read_csv(\"./Datasets/dota2_combined_player_and_none_combined_training_set.csv\", header=None, names=['index', 'text','label'])\n",
        "\n",
        "  dota_train_p_combined_sentences = dota_training_player_combined_set.text.values\n",
        "  dota_train_p_combined_labels = dota_training_player_combined_set.label.values\n",
        "\n",
        "  #Converts the string labels to numbers so they can be used in the binary classifier\n",
        "  dota_train_p_combined_labels_num = label_to_number(dota_train_p_combined_labels)\n",
        "\n",
        "  print('Number of dota 2 training sentences after concurrent player messages are combined and added to the dota 2 training set: {:,}\\n'.format(dota_train_p_combined_sentences.shape[0]))\n",
        "\n",
        "  #OLID training set\n",
        "  olid_training_set = pd.read_csv(\"./Datasets/olid-training-v1.0.tsv\", delimiter='\\t', header=None, names=['id', 'tweet', 'subtask_a', 'subtask_b','subtask_c'])\n",
        "\n",
        "  olid_train_sentences = olid_training_set.tweet.values\n",
        "  olid_train_labels = olid_training_set.subtask_a.values\n",
        "\n",
        "  #Converts the string labels to numbers so they can be used in the binary classifier\n",
        "  olid_train_labels_num = label_to_number(olid_train_labels)\n",
        "\n",
        "  print('Number of OLID training sentences: {:,}\\n'.format(olid_train_sentences.shape[0]))\n",
        "\n",
        "  #OLID and Dota 2 training sets combined\n",
        "  dota2_olid_combined_training_set = pd.read_csv(\"./Datasets/dota2_olid_combined_training_set.csv\", header=None, names=['id', 'tweet', 'subtask_a'])\n",
        "\n",
        "  dota_and_olid_train_sentences = dota2_olid_combined_training_set.tweet.values\n",
        "  dota_and_olid_train_labels = dota2_olid_combined_training_set.subtask_a.values\n",
        "\n",
        "  #Converts the string labels to numbers so they can be used in the binary classifier\n",
        "  dota_and_olid_train_labels_num = label_to_number(dota_and_olid_train_labels)\n",
        "\n",
        "  print('Number of Dota 2 and OLID training sentences: {:,}\\n'.format(dota_and_olid_train_sentences.shape[0]))\n",
        "\n",
        "  return dota_train_sentences, dota_train_labels_num, dota_train_p_combined_sentences, dota_train_p_combined_labels_num, olid_train_sentences, olid_train_labels_num, dota_and_olid_train_sentences, dota_and_olid_train_labels_num\n",
        "\n",
        "def test_data_unpacker():\n",
        "  #Dota 2 test set\n",
        "  dota_test_set = pd.read_csv(\"./Datasets/dota2_test_set.csv\", header=None, names=['index', 'local match index', 'text','label'])\n",
        "\n",
        "  dota_test_sentences = dota_test_set.text.values\n",
        "  dota_test_labels = dota_test_set.label.values\n",
        "\n",
        "  #Converts the string labels to numbers so they can be used in the binary classifier\n",
        "  dota_test_labels_num = label_to_number(dota_test_labels)\n",
        "\n",
        "  print('Number of dota 2 test sentences: {:,}\\n'.format(dota_test_sentences.shape[0]))\n",
        "\n",
        "  #OLID test set tweets and labels\n",
        "  olid_test_tweets = pd.read_csv(\"./Datasets/testset-levela.tsv\", delimiter='\\t', header=None, names=['id', 'tweet'])\n",
        "  olid_test_labels = pd.read_csv(\"./Datasets/labels-levela.csv\", header=None, names=['id', 'subtask_a'])\n",
        "\n",
        "  olid_test_sentences = olid_test_tweets.tweet.values\n",
        "  olid_test_labels = olid_test_labels.subtask_a.values\n",
        "\n",
        "  #Converts the string labels to numbers so they can be used in the binary classifier\n",
        "  olid_test_labels_num = label_to_number(olid_test_labels)\n",
        "\n",
        "  print('Number of OLID test sentences: {:,}\\n'.format(olid_test_sentences.shape[0]))\n",
        "\n",
        "  return dota_test_sentences, dota_test_labels_num, olid_test_sentences, olid_test_labels_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KocKkC2srUMP"
      },
      "source": [
        "# Function that converts labels to numerical values\n",
        "def label_to_number(labels):\n",
        "\n",
        "  # This stores the labels as numerical values so they can be used in machine learning models\n",
        "  num_labels = np.zeros(len(labels),dtype=int)\n",
        "\n",
        "  # All OFF labels are changed to 1 and NOT remain 0\n",
        "  for i in range(0,len(labels)):\n",
        "    if (labels[i] == \"OFF\"):\n",
        "      num_labels[i] = int(1)\n",
        "  return num_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UryvbK4OsBez"
      },
      "source": [
        "# Defines a function used to tokenize the data set\n",
        "def tokenize(sentences,tokenizer):\n",
        "  input_ids = []\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "  # Print sentence 0, now as a list of IDs.\n",
        "  print('Original: ', sentences[0])\n",
        "  print('Token IDs:', input_ids[0])\n",
        "  return input_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0bRgNlCs9sm"
      },
      "source": [
        "# Defines a function that returns the max sentence length for any data set\n",
        "def max_length(input_ids):\n",
        "  max_token_length = max([len(sen) for sen in input_ids])\n",
        "  print('Max sentence length: ', max_token_length)\n",
        "  return max_token_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_1eGgotOsb"
      },
      "source": [
        "# Defines a function that pads all the token text to the padded_length\n",
        "def padding_data(padded_length, input_ids):\n",
        "\n",
        "  # Padding length is chosen to be slightly larger than the maximum sentence length\n",
        "  print('\\nPadding/truncating all sentences to %d values...' % padded_length)\n",
        "\n",
        "  # Pad our input tokens with value 0.\n",
        "  # \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "  # as opposed to the beginning.\n",
        "  input_ids = pad_sequences(input_ids, maxlen=padded_length, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "  print('\\Done.')\n",
        "  return input_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY_wikV7xFTt"
      },
      "source": [
        "# Defines a function that creates attention masks for the tokenized sentences\n",
        "def create_attention_masks(input_ids):\n",
        "\n",
        "  # Initialise attention masks\n",
        "  attention_masks = []\n",
        "\n",
        "\n",
        "# For each sentence...\n",
        "  for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)\n",
        "\n",
        "  return attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQeffrPpy0Z9"
      },
      "source": [
        "# Defines a function that splits the data set into a training set and a validation set for accuracy measures during fine tuning.\n",
        "def train_validation_split_func(input_ids, num_labels, attention_masks):\n",
        "\n",
        "  # Use 90% for training and 10% for validation.\n",
        "\n",
        "  train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, num_labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "  # Do the same for the masks.\n",
        "  train_masks, validation_masks, _, _ = train_test_split(attention_masks, num_labels,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "  \n",
        "  return train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkxMDo6A0d9e"
      },
      "source": [
        " # Function to convert inputs into torch tensors\n",
        "def tensor_conversion(input):\n",
        "  # Note not for labels as they require the data type to be torch.long\n",
        "  input = torch.tensor(input)\n",
        "  return input\n",
        "\n",
        "# Function for converting labels to tensors\n",
        "def tensor_conversion_labels(input_labels):\n",
        "  # Note labels require the data type to be torch.long\n",
        "  input_labels = torch.tensor(input_labels,dtype=torch.long)\n",
        "  return input_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJorCmrK2jPC"
      },
      "source": [
        " # Function that create the DataLoader for a training set.\n",
        "def create_dataloader_train(train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels, batch_size):\n",
        " \n",
        "  # Create the DataLoader for a training set\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "  \n",
        "  # Create the DataLoader for our validation set.\n",
        "  validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "  validation_sampler = SequentialSampler(validation_data)\n",
        "  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "  return train_dataloader, validation_dataloader\n",
        "# Function that create the DataLoader for a test set.\n",
        "def create_dataloader_test(test_inputs, test_masks, test_labels, batch_size):\n",
        "  # Create the DataLoader for our test set.\n",
        "  test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "  test_sampler = SequentialSampler(test_data)\n",
        "  test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "  return test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "032oN2l53qez"
      },
      "source": [
        "# Function that creates a BERT model, can specify which one\n",
        "def model_creation_bert(model_string):\n",
        "  # Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "  # linear classification layer on top. \n",
        "  model = BertForSequenceClassification.from_pretrained(\n",
        "    model_string, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.  \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "  )\n",
        "\n",
        "  # Get all of the model's parameters as a list of tuples.\n",
        "  params = list(model.named_parameters())\n",
        "  print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "  print('==== Embedding Layer ====\\n')\n",
        "  for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "  print('\\n==== First Transformer ====\\n')\n",
        "  for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "  print('\\n==== Output Layer ====\\n')\n",
        "  for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zmcoBvbQlpo"
      },
      "source": [
        "# Function that creates the optimizer object\n",
        "def optimizer_func(model, train_dataloader):\n",
        "  #Uses the Adam optimizer with Weight decay fix\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # learning_rate \n",
        "                  eps = 1e-8 # adam_epsilon \n",
        "                )\n",
        "  # Toggle for between commenting and uncommenting for 4 or 6, 4 is default\n",
        "  # epochs = 6\n",
        "  epochs = 4\n",
        "  # Total number of training steps is number of batches * number of epochs.\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "  # Create the learning rate scheduler.\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # We do not want to warm up as want to start learning with maximum rate\n",
        "                                            num_training_steps = total_steps)\n",
        "  return optimizer, epochs, total_steps, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTMtc9tfQ3ot"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    # Changes logits to binary labels\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K-DoWPxQ6Ow"
      },
      "source": [
        "# Function that formats time, making it easier to read\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4kJtzSTRCLO"
      },
      "source": [
        "# Function that trains and validates the model\n",
        "def train_model(model,seed_val,epochs,optimizer,scheduler,train_dataloader,validation_dataloader):\n",
        "  # This training code is based on the `run_glue.py` script here:\n",
        "  # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "  # Initialise random seed everywhere\n",
        "  random.seed(seed_val)\n",
        "  np.random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "  torch.cuda.manual_seed_all(seed_val)\n",
        "  # Store the average loss after each epoch so we can plot them.\n",
        "  loss_values = []\n",
        "  # For each epoch...\n",
        "  for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps = 0\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "  return loss_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOO7gjL9Rsjt"
      },
      "source": [
        "# Function that plots a loss graph of training epochs vs the average loss after each epoch\n",
        "def loss_graph(loss_values):\n",
        "  f = pd.DataFrame(loss_values)\n",
        "  f.columns=['Loss']\n",
        "  fig = px.line(f, x=(f.index+1), y=f.Loss)\n",
        "  fig.update_layout(xaxis_title='Epoch',\n",
        "                   yaxis_title='Loss',\n",
        "                    font=dict(size=18))\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hnt0p1Rbg9S"
      },
      "source": [
        "# Function that predicts the labels with the trained model\n",
        "def prediction_model(model, prediction_dataloader, prediction_inputs):\n",
        "  # Prediction on test set\n",
        "  print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "  # Tracking variables \n",
        "  predictions , true_labels = [], []\n",
        "  # Predict \n",
        "  for batch in prediction_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "  print('DONE.')\n",
        "  return predictions, true_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZV21ii4bo6F"
      },
      "source": [
        "# Function that returns number of offensive messages in a data set\n",
        "def positive_samples(labels):\n",
        "  print('Positive samples: %d of %d (%.2f%%)' % (labels.sum(), len(labels), (labels.sum() / len(labels) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6lmfkdobuoC"
      },
      "source": [
        "# Function that flattens the logits from prediction into binary labels\n",
        "def flatten_labels(true_labels, prediction_labels):\n",
        "  # Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "  flat_predictions = [item for sublist in prediction_labels for item in sublist]\n",
        "  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "  \n",
        "  # Combine the correct labels for each batch into a single list.\n",
        "  flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "  \n",
        "  return flat_true_labels, flat_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy32cjlB0jjG"
      },
      "source": [
        "# Function that returns the binary precision and recall scores\n",
        "def precision_recall(flat_true_labels,flat_predictions):\n",
        "  prec_bin = precision_score(flat_true_labels, flat_predictions)\n",
        "  print(\"precision binary score: %.3f\"%prec_bin)\n",
        "  reca_bin = recall_score(flat_true_labels, flat_predictions)\n",
        "  print(\"recall binary score: %.3f\"%reca_bin)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRTIGyHU1e9o"
      },
      "source": [
        "# Function that calculates the F1 macro and binary scores\n",
        "def calc_f1(flat_true_labels,flat_predictions):\n",
        "  f1_macro = f1_score(flat_true_labels,flat_predictions,average='macro')\n",
        "  f1_binary = f1_score(flat_true_labels,flat_predictions)\n",
        "  print(\"F1 binary score: %.3f\"%f1_binary)\n",
        "  print(\"F1 macro score: %.3f\"%f1_macro)\n",
        "  return f1_binary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl-QB1Uexdji"
      },
      "source": [
        "# Function that calculates the MCC for a model\n",
        "def calc_matt_corrcoef(flat_true_labels, flat_predictions):\n",
        "  mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "  print('MCC: %.3f' % mcc)\n",
        "  return mcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm0IF1Lc-Uui"
      },
      "source": [
        "# Function that plots a confusion matrix for a model\n",
        "def plot_confusion_matrix(flat_true_labels,flat_predictions):\n",
        "  cm = confusion_matrix(flat_true_labels,flat_predictions)\n",
        "  plt.figure(figsize = (10,10))\n",
        "  sn.heatmap(cm, annot=True,annot_kws={\"size\": 18},robust = True, fmt=\"d\", cmap = plt.get_cmap('Greys'),xticklabels=[\"NOT\",\"OFF\"],yticklabels=[\"NOT\",\"OFF\"])\n",
        "  sn.set(font_scale=1.6) # for label size\n",
        "  plt.xlabel('predicted label',size=18)\n",
        "  plt.ylabel('true label',size=18)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csdqNT807hCZ"
      },
      "source": [
        "# Function that collects the TP, TN, FP and FN cases\n",
        "def predict_cases(flat_true_labels, flat_predictions, sentences):\n",
        "  tp = []\n",
        "  tn = []\n",
        "  fp = []\n",
        "  fn = []\n",
        "\n",
        "  for i in range(0, len(sentences)):\n",
        "    # If this the either TP or TN\n",
        "    if (flat_predictions[i] == flat_true_labels[i]):\n",
        "      # Must be TN\n",
        "      if (flat_predictions[i] == 0):\n",
        "        tn.append((sentences[i],flat_predictions[i],flat_true_labels[i]))\n",
        "      # Must be TP\n",
        "      else:\n",
        "        tp.append((sentences[i],flat_predictions[i],flat_true_labels[i]))\n",
        "    # Either FP or FN\n",
        "    else:\n",
        "      # Must be FN\n",
        "      if (flat_predictions[i] == 0):\n",
        "        fn.append((sentences[i],flat_predictions[i],flat_true_labels[i]))\n",
        "      # Must be FP\n",
        "      else:\n",
        "        fp.append((sentences[i],flat_predictions[i],flat_true_labels[i]))\n",
        "\n",
        "  return tp, tn, fp, fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1mNmb4yecxu"
      },
      "source": [
        "# **The training and test data loaded in to arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn5AauCNRwOM",
        "outputId": "5ca8a543-b43b-4262-9be9-b414f2d8e9c5"
      },
      "source": [
        "#All training data\n",
        "dota_train_sentences, dota_train_labels, dota_train_p_combined_sentences, dota_train_p_combined_labels, olid_train_sentences, olid_train_labels, dota_and_olid_train_sentences, dota_and_olid_train_labels = train_data_unpacker()\n",
        "\n",
        "#All test data\n",
        "dota_test_sentences, dota_test_labels, olid_test_sentences, olid_test_labels = test_data_unpacker()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of dota 2 training sentences: 14,913\n",
            "\n",
            "Number of dota 2 training sentences after concurrent player messages are combined and added to the dota 2 training set: 17,612\n",
            "\n",
            "Number of OLID training sentences: 13,240\n",
            "\n",
            "Number of Dota 2 and OLID training sentences: 28,153\n",
            "\n",
            "Number of dota 2 test sentences: 1,508\n",
            "\n",
            "Number of OLID test sentences: 860\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCy52rz-UnQ5"
      },
      "source": [
        "# **Train BERT with OLID**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "03b8e22bb7864a2f93d5608c117f0f61",
            "d490d60267f542c7bc603402ae9acd36",
            "16dc50f1981a4ce0ae577795a0e6b17e",
            "68cacfdc20814366ad2c3393909c99c9",
            "f3129240e2054d87abf6d8a9514812aa",
            "8401c6a4df684b8a9f4bb6d321fa858a",
            "8a3842e2d829418c8fc284048f6dc760",
            "87a575a177744b6c8e5b5d872723b78a",
            "f2bc03b7f2574d3abfe3abe3ee3e4ec7",
            "f9a96d9e68bd44e7a864c114368e4675",
            "7ec124e81c974d47a4a39f02ced8598c",
            "e65b7c22d26d4f19a38fc26a2fc7e161",
            "79b477aaf68644fe80a55416ec8a530d",
            "4399770293fd43e8b44077729a0f719a",
            "fd3c069f723249e0aaf74ce8ba9ffc1d",
            "558029770a644efe8a09722696a1290e",
            "5bae9f79905d4bf4b52edbac9f37dd35",
            "ad540df0bac44d879ee767dfa509c7d2",
            "6a14133cb91b41c998c184f1bbf6b211",
            "72a494b5ecaa4a1a901dd90be536ff12",
            "5e6bdeddc0f04f58b3bf47b77174930b",
            "be0db0e9fa804baea36bbec4e5d6534b",
            "85ff093064a24aa380b385c892a73900",
            "ad862c91a72a4d158400644697673d0e"
          ]
        },
        "id": "KA01xcM6WfMv",
        "outputId": "e589a99f-32c8-4fb1-a46b-a77f51e11c06"
      },
      "source": [
        "# Toggle comments for different tokenizers, use tokenizer for model intended to be used\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
        "\n",
        "#The input ids for OLID\n",
        "olid_input_ids = tokenize(olid_train_sentences,tokenizer)\n",
        "\n",
        "max_length(olid_input_ids)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "olid_padding_length = 184\n",
        "\n",
        "# Padded OLID IDs\n",
        "olid_input_ids = padding_data(olid_padding_length, olid_input_ids)\n",
        "\n",
        "olid_train_attention_masks = create_attention_masks(olid_input_ids)\n",
        "\n",
        "olid_train_inputs, olid_validation_inputs, olid_train_labels, olid_validation_labels, olid_train_masks, olid_validation_masks = train_validation_split_func(olid_input_ids, olid_train_labels, olid_train_attention_masks)\n",
        "\n",
        "# Tensor conversions\n",
        "olid_train_inputs = tensor_conversion(olid_train_inputs)\n",
        "olid_validation_inputs = tensor_conversion(olid_validation_inputs)\n",
        "\n",
        "olid_train_labels = tensor_conversion_labels(olid_train_labels)\n",
        "olid_validation_labels = tensor_conversion_labels(olid_validation_labels)\n",
        "\n",
        "olid_train_masks = tensor_conversion(olid_train_masks)\n",
        "olid_validation_masks = tensor_conversion(olid_validation_masks)\n",
        "\n",
        "# batch size specificed here, toggle comments to change it\n",
        "batch_size = 32\n",
        "#batch_size = 64\n",
        "#batch_size = 16\n",
        "\n",
        "#OLID train and validation DataLoaders\n",
        "olid_train_dataloader, olid_validation_dataloader = create_dataloader_train(olid_train_inputs, olid_train_masks, olid_train_labels, olid_validation_inputs, olid_validation_masks, olid_validation_labels, batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03b8e22bb7864a2f93d5608c117f0f61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2bc03b7f2574d3abfe3abe3ee3e4ec7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bae9f79905d4bf4b52edbac9f37dd35",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:  @USER She should ask a few native Americans what their take on this is.\n",
            "Token IDs: [101, 1030, 5310, 2016, 2323, 3198, 1037, 2261, 3128, 4841, 2054, 2037, 2202, 2006, 2023, 2003, 1012, 102]\n",
            "Max sentence length:  171\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Padding/truncating all sentences to 184 values...\n",
            "\\Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4c705c5c0bd04ce696fd201f12dbb80f",
            "bb8816bdddd448ee90423359904da048",
            "5a2d70ee8491428c84793a806b215c21",
            "7e04eb259b154680b4edc0500ce04860",
            "8aafc3f2715441999ef9e409f6a0fc93",
            "b739c85fa00c427fad743d8589d6f843",
            "a70c415b215d4925b6cf2f61d0412db5",
            "23e357215ff14762804abd40c8ec6489",
            "9ddea46da9524084a2a050adf3e3cc5a",
            "74b05bdff49f42718204628db5ba6389",
            "576bb3b079ab48e9aa3d8462ad6e6e2b",
            "da8d5a7221c541b3a70af04d87fad45a",
            "b3af0f09f88e4f4a94e319cd41bd4f9d",
            "2c26c8abcb54479bbe123fcf9186ed00",
            "e347f235d91a452c9ace2ebf914c915a",
            "382ac2f9018c4c2ca48c7c38b1b082bc"
          ]
        },
        "id": "UoH0L-mPLfqh",
        "outputId": "55e89f14-93d5-40a7-da2f-b9a327c62b50"
      },
      "source": [
        "# Initialise OLID model, toggle comments for model selection\n",
        "olid_model = model_creation_bert(\"bert-base-uncased\")\n",
        "#olid_model = model_creation_bert(\"bert-large-uncased\")\n",
        "\n",
        "# Get the optimizer, hyper parameters and scheduler for OLID\n",
        "olid_optimizer, olid_epochs, olid_total_steps, olid_scheduler = optimizer_func(olid_model,olid_train_dataloader)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "olid_model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c705c5c0bd04ce696fd201f12dbb80f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ddea46da9524084a2a050adf3e3cc5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vNN3ZOxD_9d",
        "outputId": "2d712bd7-c823-4726-bd87-446ce61fe366"
      },
      "source": [
        "olid_seed_val = 20\n",
        "\n",
        "#Trains the OLID model\n",
        "\n",
        "olid_loss_values = train_model(olid_model, olid_seed_val, olid_epochs, olid_optimizer, olid_scheduler, olid_train_dataloader,olid_validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    373.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    373.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    373.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    373.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    373.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    373.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    373.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    373.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    373.    Elapsed: 0:01:52.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epoch took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    373.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    373.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    373.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    373.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    373.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    373.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    373.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    373.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    373.    Elapsed: 0:01:52.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epoch took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    373.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    373.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    373.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    373.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    373.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    373.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    373.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    373.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    373.    Elapsed: 0:01:52.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epoch took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    373.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    373.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    373.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    373.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    373.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    373.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    373.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    373.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    373.    Elapsed: 0:01:52.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epoch took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaIdgjj4EmvM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "6818e2ed-0801-468a-b85b-7608542887d4"
      },
      "source": [
        "# Plot loss graph for OLID\n",
        "loss_graph(olid_loss_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"495a43bf-42e7-417b-92de-5b15d5fb87f9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"495a43bf-42e7-417b-92de-5b15d5fb87f9\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '495a43bf-42e7-417b-92de-5b15d5fb87f9',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4], \"xaxis\": \"x\", \"y\": [0.4760250752796756, 0.36754040703696794, 0.27291801709671765, 0.20699679188370385], \"yaxis\": \"y\"}],\n",
              "                        {\"font\": {\"size\": 18}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('495a43bf-42e7-417b-92de-5b15d5fb87f9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc7c4FSykbOV"
      },
      "source": [
        "# **Test BERT with OLID on OLID test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLWfMmyvRVCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30011d8-7bd6-4c16-cf7d-62f421d3f416"
      },
      "source": [
        "\n",
        "# OLID test input IDs\n",
        "olid_test_input_ids = tokenize(olid_test_sentences,tokenizer)\n",
        "\n",
        "max_length(olid_test_input_ids)\n",
        "\n",
        "# OLID test input IDs padded\n",
        "olid_test_input_ids = padding_data(olid_padding_length,olid_test_input_ids)\n",
        "\n",
        "olid_test_attention_masks = create_attention_masks(olid_test_input_ids)\n",
        "\n",
        "# Convert to tensors.\n",
        "olid_prediction_inputs = tensor_conversion(olid_test_input_ids)\n",
        "olid_prediction_masks = tensor_conversion(olid_test_attention_masks)\n",
        "olid_prediction_labels = tensor_conversion_labels(olid_test_labels)\n",
        "\n",
        "# Prediction DataLoader for OLID test set\n",
        "\n",
        "olid_prediction_dataloader = create_dataloader_test(olid_prediction_inputs, olid_prediction_masks, olid_prediction_labels, batch_size)\n",
        "\n",
        "\n",
        "# Predict labels of OLID test set with the OLID model\n",
        "olid_predictions, olid_true_labels = prediction_model(olid_model, olid_prediction_dataloader,olid_prediction_inputs)\n",
        "\n",
        "positive_samples(olid_test_labels)\n",
        "\n",
        "olid_flat_true_labels, olid_flat_predictions = flatten_labels(olid_true_labels, olid_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA Democrats Support Antifa, Muslim Brotherhood, MS13, ISIS, Pedophilia, Child Trafficking, Taxpayer Funded Abortion’s, Election Fraud, Sedition And Treason!!! #LockThemAllUp #WWG1WGA #QAnon ⁦@USER URL\n",
            "Token IDs: [101, 1001, 2040, 2483, 4160, 1001, 2073, 3367, 15689, 2121, 6299, 1001, 15653, 8238, 2063, 1001, 11703, 8523, 8873, 3736, 8037, 2490, 3424, 7011, 1010, 5152, 12865, 1010, 5796, 17134, 1010, 18301, 1010, 21877, 3527, 21850, 6632, 1010, 2775, 11626, 1010, 26980, 6787, 11324, 1521, 1055, 1010, 2602, 9861, 1010, 7367, 20562, 1998, 14712, 999, 999, 999, 1001, 5843, 10760, 9067, 7630, 2361, 1001, 1059, 27767, 2487, 27767, 2050, 1001, 1053, 6761, 2078, 1030, 5310, 24471, 2140, 102]\n",
            "Max sentence length:  94\n",
            "\n",
            "Padding/truncating all sentences to 184 values...\n",
            "\\Done.\n",
            "Predicting labels for 860 test sentences...\n",
            "DONE.\n",
            "Positive samples: 240 of 860 (27.91%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udxl7PKg4Z_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657d579a-c399-44e7-f57c-1e334f365483"
      },
      "source": [
        "#Performance metrics\n",
        "\n",
        "# Calculate the MCC\n",
        "olid_mcc = calc_matt_corrcoef(olid_flat_true_labels, olid_flat_predictions)\n",
        "\n",
        "# Calculate the F1, binary and macro scores\n",
        "olid_f1 = calc_f1(olid_flat_true_labels,olid_flat_predictions)\n",
        "\n",
        "# Calculate the precisiona nd recall scores\n",
        "precision_recall(olid_flat_true_labels,olid_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.599\n",
            "F1 binary score: 0.707\n",
            "F1 macro score: 0.799\n",
            "precision binary score: 0.732\n",
            "recall binary score: 0.683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WA2irWp_UKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "e5991c7f-b950-4b7a-8183-787733ae6470"
      },
      "source": [
        "# Plot confusion matrix of the OLID model's predictions on the OLID test set\n",
        "plot_confusion_matrix(olid_flat_true_labels,olid_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Re5EyDl88VK"
      },
      "source": [
        "# OLID TP, TN, FP, FN\n",
        "olid_tp, olid_tn, olid_fp, olid_fn = predict_cases(olid_flat_true_labels,olid_flat_predictions, olid_test_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tkU1WDkze4"
      },
      "source": [
        "# **Test BERT with OLID on Dota 2 test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-P3VxRxkC1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef3bde1-6499-41c3-f255-33e90b388de4"
      },
      "source": [
        "#This is code to convert the dota test set to be used by the models\n",
        "\n",
        "# Dota 2 test input IDs \n",
        "dota_test_input_ids = tokenize(dota_test_sentences,tokenizer)\n",
        "\n",
        "max_length(dota_test_input_ids)\n",
        "\n",
        "# Dota 2 test input IDs padded\n",
        "dota_test_input_ids = padding_data(84,dota_test_input_ids)\n",
        "\n",
        "dota_test_attention_masks = create_attention_masks(dota_test_input_ids)\n",
        "\n",
        "# Convert to tensors.\n",
        "dota_prediction_inputs = tensor_conversion(dota_test_input_ids)\n",
        "dota_prediction_masks = tensor_conversion(dota_test_attention_masks)\n",
        "dota_prediction_labels = tensor_conversion_labels(dota_test_labels)\n",
        "\n",
        "# Dota 2 test set DataLoader\n",
        "dota_prediction_dataloader = create_dataloader_test(dota_prediction_inputs, dota_prediction_masks, dota_prediction_labels, batch_size)\n",
        "\n",
        "positive_samples(dota_test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  gg\n",
            "Token IDs: [101, 1043, 2290, 102]\n",
            "Max sentence length:  29\n",
            "\n",
            "Padding/truncating all sentences to 84 values...\n",
            "\\Done.\n",
            "Positive samples: 254 of 1508 (16.84%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-iLsesulCa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc803170-712f-4691-9178-d79088c07377"
      },
      "source": [
        "# Predict Dota 2 test set with OLID model\n",
        "olid_on_dota_predictions, olid_on_dota_true_labels = prediction_model(olid_model, dota_prediction_dataloader,dota_prediction_inputs)\n",
        "\n",
        "olid_on_dota_flat_true_labels, olid_on_dota_flat_predictions = flatten_labels(olid_on_dota_true_labels, olid_on_dota_predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,508 test sentences...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqgg37FN4sWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3b4a2a-5e32-4d43-ed96-6e078812ded0"
      },
      "source": [
        "#Results...\n",
        "\n",
        "# Calculate the MCC\n",
        "dota_mcc = calc_matt_corrcoef(olid_on_dota_flat_true_labels, olid_on_dota_flat_predictions)\n",
        "\n",
        "# Calculate the precision and recall scores\n",
        "precision_recall(olid_on_dota_flat_true_labels,olid_on_dota_flat_predictions)\n",
        "\n",
        "# Calculate the F1, binary and macro scores\n",
        "olid_on_dota_f1 = calc_f1(olid_on_dota_flat_true_labels,olid_on_dota_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.300\n",
            "precision binary score: 0.556\n",
            "recall binary score: 0.256\n",
            "F1 binary score: 0.350\n",
            "F1 macro score: 0.630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsLmYfnwmbS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "e113a1aa-7840-4610-ffed-a41037b556db"
      },
      "source": [
        "# Plot confusion matrix for the Dota 2 set predicted by the OLID model\n",
        "plot_confusion_matrix(olid_on_dota_flat_true_labels,olid_on_dota_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB3UYfJ8kfRA"
      },
      "source": [
        "# TP, TN, FP and FN for Dota 2 test set predicted with OLID model\n",
        "olid_dota_tp, olid_dota_tn, olid_dota_fp, olid_dota_fn = predict_cases(olid_on_dota_flat_true_labels,olid_on_dota_flat_predictions, dota_test_sentences)\n",
        "\n",
        "tp_exp = pd.DataFrame(data = olid_dota_tp,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "tp_exp.to_csv('olid_dota2_tp.csv',index = False)\n",
        "\n",
        "tn_exp = pd.DataFrame(data = olid_dota_tn,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "tn_exp.to_csv('olid_dota2_tn.csv',index = False)\n",
        "\n",
        "fp_exp = pd.DataFrame(data = olid_dota_fp,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "fp_exp.to_csv('olid_dota2_fp.csv',index = False)\n",
        "\n",
        "fn_exp = pd.DataFrame(data = olid_dota_fn,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "fn_exp.to_csv('olid_dota2_fn.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQHXCjkyms02"
      },
      "source": [
        "# **Train BERT with Dota 2 training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS1GJ7tdrGSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6a57f9-023f-40c4-b661-5260ff216bc4"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Dota 2 training set input IDs\n",
        "dota_input_ids = tokenize(dota_train_sentences,tokenizer)\n",
        "\n",
        "max_length(dota_input_ids)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Dota 2 training set input IDs padded\n",
        "dota_input_ids = padding_data(84,dota_input_ids)\n",
        "\n",
        "dota_attention_masks = create_attention_masks(dota_input_ids)\n",
        "\n",
        "dota_train_inputs, dota_validation_inputs, dota_train_labels, dota_validation_labels, dota_train_masks, dota_validation_masks = train_validation_split_func(dota_input_ids, dota_train_labels, dota_attention_masks)\n",
        "\n",
        "# Tensor conversion\n",
        "dota_train_inputs = tensor_conversion(dota_train_inputs)\n",
        "dota_validation_inputs = tensor_conversion(dota_validation_inputs)\n",
        "\n",
        "dota_train_labels = tensor_conversion_labels(dota_train_labels)\n",
        "dota_validation_labels = tensor_conversion_labels(dota_validation_labels)\n",
        "\n",
        "dota_train_masks = tensor_conversion(dota_train_masks)\n",
        "dota_validation_masks = tensor_conversion(dota_validation_masks)\n",
        "\n",
        "# The DataLoader for Dota 2 training and validation\n",
        "\n",
        "batch_size = 32\n",
        "dota_train_dataloader, dota_validation_dataloader = create_dataloader_train(dota_train_inputs, dota_train_masks, dota_train_labels, dota_validation_inputs, dota_validation_masks, dota_validation_labels, batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  why do people always play clinkz in turbo\n",
            "Token IDs: [101, 2339, 2079, 2111, 2467, 2377, 18856, 19839, 2480, 1999, 15386, 102]\n",
            "Max sentence length:  77\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Padding/truncating all sentences to 84 values...\n",
            "\\Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bXjbZIelJGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f1e40e-275e-47c3-fa65-750ffbb7078c"
      },
      "source": [
        "# Dota 2 model object\n",
        "dota_model = model_creation_bert(\"bert-base-uncased\")\n",
        "\n",
        "# Dota 2 optimizer object, hyper paramaters and scheduler\n",
        "dota_optimizer, dota_epochs, dota_total_steps, dota_scheduler = optimizer_func(dota_model,dota_train_dataloader)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "dota_model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxuUC8BOlec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76d8a58-70d2-4d93-cc7b-d028e5801d56"
      },
      "source": [
        "dota_seed_val = 42\n",
        "# Trains the Dota 2 model\n",
        "dota_loss_values = train_model(dota_model, dota_seed_val, dota_epochs, dota_optimizer, dota_scheduler, dota_train_dataloader, dota_validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    420.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    420.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    420.    Elapsed: 0:00:19.\n",
            "  Batch   160  of    420.    Elapsed: 0:00:26.\n",
            "  Batch   200  of    420.    Elapsed: 0:00:32.\n",
            "  Batch   240  of    420.    Elapsed: 0:00:38.\n",
            "  Batch   280  of    420.    Elapsed: 0:00:45.\n",
            "  Batch   320  of    420.    Elapsed: 0:00:51.\n",
            "  Batch   360  of    420.    Elapsed: 0:00:58.\n",
            "  Batch   400  of    420.    Elapsed: 0:01:04.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epoch took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    420.    Elapsed: 0:00:06.\n",
            "  Batch    80  of    420.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    420.    Elapsed: 0:00:19.\n",
            "  Batch   160  of    420.    Elapsed: 0:00:25.\n",
            "  Batch   200  of    420.    Elapsed: 0:00:32.\n",
            "  Batch   240  of    420.    Elapsed: 0:00:38.\n",
            "  Batch   280  of    420.    Elapsed: 0:00:45.\n",
            "  Batch   320  of    420.    Elapsed: 0:00:51.\n",
            "  Batch   360  of    420.    Elapsed: 0:00:57.\n",
            "  Batch   400  of    420.    Elapsed: 0:01:04.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epoch took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    420.    Elapsed: 0:00:06.\n",
            "  Batch    80  of    420.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    420.    Elapsed: 0:00:19.\n",
            "  Batch   160  of    420.    Elapsed: 0:00:25.\n",
            "  Batch   200  of    420.    Elapsed: 0:00:32.\n",
            "  Batch   240  of    420.    Elapsed: 0:00:38.\n",
            "  Batch   280  of    420.    Elapsed: 0:00:44.\n",
            "  Batch   320  of    420.    Elapsed: 0:00:50.\n",
            "  Batch   360  of    420.    Elapsed: 0:00:57.\n",
            "  Batch   400  of    420.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epoch took: 0:01:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    420.    Elapsed: 0:00:06.\n",
            "  Batch    80  of    420.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    420.    Elapsed: 0:00:19.\n",
            "  Batch   160  of    420.    Elapsed: 0:00:25.\n",
            "  Batch   200  of    420.    Elapsed: 0:00:31.\n",
            "  Batch   240  of    420.    Elapsed: 0:00:38.\n",
            "  Batch   280  of    420.    Elapsed: 0:00:44.\n",
            "  Batch   320  of    420.    Elapsed: 0:00:50.\n",
            "  Batch   360  of    420.    Elapsed: 0:00:57.\n",
            "  Batch   400  of    420.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:01:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otv2g7UYDs5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "9b67c42b-f01c-45a2-97d8-d080bd7dfe7f"
      },
      "source": [
        "# Plots average loss graph\n",
        "loss_graph(dota_loss_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"4cddc30a-e75e-46ff-8b3e-aa0ed8b895f3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"4cddc30a-e75e-46ff-8b3e-aa0ed8b895f3\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '4cddc30a-e75e-46ff-8b3e-aa0ed8b895f3',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4], \"xaxis\": \"x\", \"y\": [0.19009544719287771, 0.08274510540899688, 0.043915231084351296, 0.02486139272916175], \"yaxis\": \"y\"}],\n",
              "                        {\"font\": {\"size\": 18}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4cddc30a-e75e-46ff-8b3e-aa0ed8b895f3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXu1zt7nrGm"
      },
      "source": [
        "# **Test BERT with Dota 2 on Dota 2 test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYDfMuCRTNXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab13926-65a2-416a-acff-5466f1a65c8a"
      },
      "source": [
        "# Predicts Dota 2 test set with Dota 2 model\n",
        "dota_predictions, dota_true_labels = prediction_model(dota_model, dota_prediction_dataloader,dota_prediction_inputs)\n",
        "\n",
        "positive_samples(dota_test_labels)\n",
        "\n",
        "dota_flat_true_labels, dota_flat_predictions = flatten_labels(dota_true_labels, dota_predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,508 test sentences...\n",
            "DONE.\n",
            "Positive samples: 254 of 1508 (16.84%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRdHXjRz47Af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8ba68d-bbc1-4966-e07d-fcbcbf134d4d"
      },
      "source": [
        "# Calculate the MCC\n",
        "dota_mcc = calc_matt_corrcoef(dota_flat_true_labels, dota_flat_predictions)\n",
        "\n",
        "# Calculate the precision and recall\n",
        "precision_recall(dota_flat_true_labels,dota_flat_predictions)\n",
        "\n",
        "# Calculate the F1, binary and macro scores\n",
        "dota_f1 = calc_f1(dota_flat_true_labels,dota_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.863\n",
            "precision binary score: 0.954\n",
            "recall binary score: 0.819\n",
            "F1 binary score: 0.881\n",
            "F1 macro score: 0.930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFioCcs8UEik",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "cbefde8c-f763-4538-bad7-a37b70db1a34"
      },
      "source": [
        "# Plot confusion matrix for Dota 2 model\n",
        "plot_confusion_matrix(dota_flat_true_labels,dota_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeRQhK18jiFi"
      },
      "source": [
        "# TP, TN, FP, FN for Dota 2 model predicting Dota 2 test set\n",
        "dota_tp, dota_tn, dota_fp, dota_fn = predict_cases(dota_flat_true_labels,dota_flat_predictions, dota_test_sentences)\n",
        "\n",
        "\n",
        "# Exports above to files\n",
        "dota_tp_exp = pd.DataFrame(data = dota_tp,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "dota_tp_exp.to_csv('dota2_tp.csv',index = False)\n",
        "\n",
        "dota_tn_exp = pd.DataFrame(data = dota_tn,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "dota_tn_exp.to_csv('dota2_tn.csv',index = False)\n",
        "\n",
        "dota_fp_exp = pd.DataFrame(data = dota_fp,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "dota_fp_exp.to_csv('dota2_fp.csv',index = False)\n",
        "\n",
        "dota_fn_exp = pd.DataFrame(data = dota_fn,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "dota_fn_exp.to_csv('dota2_fn.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNROBBDWpNWD"
      },
      "source": [
        "# **Train BERT with OLID and Dota 2 model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzB7W3Zwz71n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c428bc7-de6b-46c9-bed5-f1d39a03305c"
      },
      "source": [
        "# OLID and Dota 2 model \n",
        "\n",
        "dota_and_olid_train_input_ids = tokenize(dota_and_olid_train_sentences,tokenizer)\n",
        "\n",
        "dota_and_olid_input_ids = padding_data(184,dota_and_olid_train_input_ids)\n",
        "\n",
        "dota_and_olid_attention_masks = create_attention_masks(dota_and_olid_input_ids)\n",
        "\n",
        "dota_and_olid_train_inputs, dota_and_olid_validation_inputs, dota_and_olid_train_labels, dota_and_olid_validation_labels, dota_and_olid_train_masks, dota_and_olid_validation_masks = train_validation_split_func(dota_and_olid_input_ids, dota_and_olid_train_labels, dota_and_olid_attention_masks)\n",
        "\n",
        "dota_and_olid_train_inputs = tensor_conversion(dota_and_olid_train_inputs)\n",
        "dota_and_olid_validation_inputs = tensor_conversion(dota_and_olid_validation_inputs)\n",
        "\n",
        "dota_and_olid_train_labels = tensor_conversion_labels(dota_and_olid_train_labels)\n",
        "dota_and_olid_validation_labels = tensor_conversion_labels(dota_and_olid_validation_labels)\n",
        "\n",
        "dota_and_olid_train_masks = tensor_conversion(dota_and_olid_train_masks)\n",
        "dota_and_olid_validation_masks = tensor_conversion(dota_and_olid_validation_masks)\n",
        "\n",
        "batch_size = 32\n",
        "# batch_size = 64\n",
        "dota_and_olid_train_dataloader, dota_and_olid_validation_dataloader = create_dataloader_train(dota_and_olid_train_inputs, dota_and_olid_train_masks, dota_and_olid_train_labels, dota_and_olid_validation_inputs, dota_and_olid_validation_masks, dota_and_olid_validation_labels, batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  @USER She should ask a few native Americans what their take on this is.\n",
            "Token IDs: [101, 1030, 5310, 2016, 2323, 3198, 1037, 2261, 3128, 4841, 2054, 2037, 2202, 2006, 2023, 2003, 1012, 102]\n",
            "\n",
            "Padding/truncating all sentences to 184 values...\n",
            "\\Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmJ8eHABqdOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b7551d-e96a-422a-eaec-c6997a198815"
      },
      "source": [
        "# Model object for OLID and Dota 2 model\n",
        "dota_and_olid_model = model_creation_bert(\"bert-base-uncased\")\n",
        "\n",
        "dota_and_olid_optimizer, dota_and_olid_epochs, dota_and_olid_total_steps, dota_and_olid_scheduler = optimizer_func(dota_and_olid_model,dota_and_olid_train_dataloader)\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "dota_and_olid_model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErKzznigqzKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfd6a5d-ad1a-4f08-c689-5c066a85a8c8"
      },
      "source": [
        "dota_and_olid_seed_val = 59\n",
        "#Training phase of OLID and Dota 2 model\n",
        "dota_and_olid_loss_values = train_model(dota_and_olid_model, dota_and_olid_seed_val, dota_and_olid_epochs, dota_and_olid_optimizer, dota_and_olid_scheduler, dota_and_olid_train_dataloader,dota_and_olid_validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    792.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    792.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    792.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    792.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    792.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    792.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    792.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    792.    Elapsed: 0:01:39.\n",
            "  Batch   360  of    792.    Elapsed: 0:01:52.\n",
            "  Batch   400  of    792.    Elapsed: 0:02:04.\n",
            "  Batch   440  of    792.    Elapsed: 0:02:17.\n",
            "  Batch   480  of    792.    Elapsed: 0:02:29.\n",
            "  Batch   520  of    792.    Elapsed: 0:02:42.\n",
            "  Batch   560  of    792.    Elapsed: 0:02:54.\n",
            "  Batch   600  of    792.    Elapsed: 0:03:06.\n",
            "  Batch   640  of    792.    Elapsed: 0:03:19.\n",
            "  Batch   680  of    792.    Elapsed: 0:03:31.\n",
            "  Batch   720  of    792.    Elapsed: 0:03:44.\n",
            "  Batch   760  of    792.    Elapsed: 0:03:57.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epoch took: 0:04:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    792.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    792.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    792.    Elapsed: 0:00:38.\n",
            "  Batch   160  of    792.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    792.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    792.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    792.    Elapsed: 0:01:28.\n",
            "  Batch   320  of    792.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    792.    Elapsed: 0:01:53.\n",
            "  Batch   400  of    792.    Elapsed: 0:02:05.\n",
            "  Batch   440  of    792.    Elapsed: 0:02:18.\n",
            "  Batch   480  of    792.    Elapsed: 0:02:30.\n",
            "  Batch   520  of    792.    Elapsed: 0:02:43.\n",
            "  Batch   560  of    792.    Elapsed: 0:02:55.\n",
            "  Batch   600  of    792.    Elapsed: 0:03:08.\n",
            "  Batch   640  of    792.    Elapsed: 0:03:20.\n",
            "  Batch   680  of    792.    Elapsed: 0:03:33.\n",
            "  Batch   720  of    792.    Elapsed: 0:03:45.\n",
            "  Batch   760  of    792.    Elapsed: 0:03:58.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epoch took: 0:04:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    792.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    792.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    792.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    792.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    792.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    792.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    792.    Elapsed: 0:01:28.\n",
            "  Batch   320  of    792.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    792.    Elapsed: 0:01:53.\n",
            "  Batch   400  of    792.    Elapsed: 0:02:05.\n",
            "  Batch   440  of    792.    Elapsed: 0:02:18.\n",
            "  Batch   480  of    792.    Elapsed: 0:02:30.\n",
            "  Batch   520  of    792.    Elapsed: 0:02:43.\n",
            "  Batch   560  of    792.    Elapsed: 0:02:55.\n",
            "  Batch   600  of    792.    Elapsed: 0:03:08.\n",
            "  Batch   640  of    792.    Elapsed: 0:03:20.\n",
            "  Batch   680  of    792.    Elapsed: 0:03:33.\n",
            "  Batch   720  of    792.    Elapsed: 0:03:45.\n",
            "  Batch   760  of    792.    Elapsed: 0:03:58.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epoch took: 0:04:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    792.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    792.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    792.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    792.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    792.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    792.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    792.    Elapsed: 0:01:28.\n",
            "  Batch   320  of    792.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    792.    Elapsed: 0:01:53.\n",
            "  Batch   400  of    792.    Elapsed: 0:02:05.\n",
            "  Batch   440  of    792.    Elapsed: 0:02:18.\n",
            "  Batch   480  of    792.    Elapsed: 0:02:30.\n",
            "  Batch   520  of    792.    Elapsed: 0:02:43.\n",
            "  Batch   560  of    792.    Elapsed: 0:02:55.\n",
            "  Batch   600  of    792.    Elapsed: 0:03:08.\n",
            "  Batch   640  of    792.    Elapsed: 0:03:20.\n",
            "  Batch   680  of    792.    Elapsed: 0:03:33.\n",
            "  Batch   720  of    792.    Elapsed: 0:03:45.\n",
            "  Batch   760  of    792.    Elapsed: 0:03:58.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epoch took: 0:04:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq8xsCgTpg5l"
      },
      "source": [
        "# **Test BERT with OLID and Dota 2 on Dota 2 test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBbFd2yPyuv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66abceb-7e63-4f64-ba62-87a4d2e76464"
      },
      "source": [
        "# Predictions for Dota 2 test set with OLID and Dota 2 model\n",
        "dota_and_olid_predictions, dota_and_olid_true_labels = prediction_model(dota_and_olid_model, dota_prediction_dataloader,dota_prediction_inputs)\n",
        "\n",
        "dota_and_olid_flat_true_labels, dota_and_olid_flat_predictions = flatten_labels(dota_and_olid_true_labels, dota_and_olid_predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,508 test sentences...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFVKZQ03y_wJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5d69ac-f2b3-4855-ecf9-1eadbddcccbb"
      },
      "source": [
        "#Results...\n",
        "\n",
        "# Calculate the MCC\n",
        "dota_and_olid_mcc = calc_matt_corrcoef(dota_and_olid_flat_true_labels, dota_and_olid_flat_predictions)\n",
        "\n",
        "# Calculate the precision and recall\n",
        "precision_recall(dota_and_olid_flat_true_labels,dota_and_olid_flat_predictions)\n",
        "\n",
        "# Calculate the F1 score, binary and macro\n",
        "dota_and_olid_f1 = calc_f1(dota_and_olid_flat_true_labels,dota_and_olid_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.856\n",
            "precision binary score: 0.937\n",
            "recall binary score: 0.823\n",
            "F1 binary score: 0.876\n",
            "F1 macro score: 0.927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcp_EEHip0eP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "5de6280d-3531-4636-808b-f9c2c9d87a80"
      },
      "source": [
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(dota_and_olid_flat_true_labels,dota_and_olid_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W88nwtfUzArP"
      },
      "source": [
        "# TP, TN, FP, FN for Dota 2 model predicting Dota 2 test set\n",
        "dota_and_olid_tp, dota_and_olid_tn, dota_and_olid_fp, dota_and_olid_fn = predict_cases(dota_and_olid_flat_true_labels,dota_and_olid_flat_predictions, dota_test_sentences)\n",
        "\n",
        "tp_exp = pd.DataFrame(data = dota_and_olid_tp,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "tp_exp.to_csv('dota_and_olid_tp.csv',index = False)\n",
        "\n",
        "tn_exp = pd.DataFrame(data = dota_and_olid_tn,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "tn_exp.to_csv('dota_and_olid_tn.csv',index = False)\n",
        "\n",
        "fp_exp = pd.DataFrame(data = dota_and_olid_fp,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "fp_exp.to_csv('dota_and_olid_fp.csv',index = False)\n",
        "\n",
        "fn_exp = pd.DataFrame(data = dota_and_olid_fn,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "fn_exp.to_csv('dota_and_olid_fn.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt4Rf47eq-SP"
      },
      "source": [
        "# **Train BERT with Dota 2 and player combined messages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fVRCT6Hqevl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ece9fb0-9be6-4c2b-a4e6-b83e07d7228c"
      },
      "source": [
        "# Dota 2 and player combined messages model\n",
        "\n",
        "dota_p_combined_input_ids = tokenize(dota_train_p_combined_sentences,tokenizer)\n",
        "\n",
        "dota_p_combined_input_ids = padding_data(84,dota_p_combined_input_ids)\n",
        "\n",
        "dota_p_combined_attention_masks = create_attention_masks(dota_p_combined_input_ids)\n",
        "\n",
        "dota_p_combined_train_inputs, dota_p_combined_validation_inputs, dota_p_combined_train_labels, dota_p_combined_validation_labels, dota_p_combined_train_masks, dota_p_combined_validation_masks = train_validation_split_func(dota_p_combined_input_ids, dota_train_p_combined_labels, dota_p_combined_attention_masks)\n",
        "\n",
        "dota_p_combined_train_inputs = tensor_conversion(dota_p_combined_train_inputs)\n",
        "dota_p_combined_validation_inputs = tensor_conversion(dota_p_combined_validation_inputs)\n",
        "\n",
        "dota_p_combined_train_labels = tensor_conversion_labels(dota_p_combined_train_labels)\n",
        "dota_p_combined_validation_labels = tensor_conversion_labels(dota_p_combined_validation_labels)\n",
        "\n",
        "dota_p_combined_train_masks = tensor_conversion(dota_p_combined_train_masks)\n",
        "dota_p_combined_validation_masks = tensor_conversion(dota_p_combined_validation_masks)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "dota_p_combined_train_dataloader, dota_p_combined_validation_dataloader = create_dataloader_train(dota_p_combined_train_inputs, dota_p_combined_train_masks, dota_p_combined_train_labels, dota_p_combined_validation_inputs, dota_p_combined_validation_masks, dota_p_combined_validation_labels, batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  why do people always play clinkz in turbo\n",
            "Token IDs: [101, 2339, 2079, 2111, 2467, 2377, 18856, 19839, 2480, 1999, 15386, 102]\n",
            "\n",
            "Padding/truncating all sentences to 84 values...\n",
            "\\Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz1jV8DEsZ8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e896bdff-483b-4ac3-bab0-13699c424db4"
      },
      "source": [
        "# Model object for Dota 2 and player combined messages model\n",
        "dota_p_combined_model = model_creation_bert(\"bert-base-uncased\")\n",
        "\n",
        "dota_p_combined_optimizer, dota_p_combined_epochs, dota_p_combined_total_steps, dota_p_combined_scheduler = optimizer_func(dota_p_combined_model,dota_p_combined_train_dataloader)\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "dota_p_combined_model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in45mljPstbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc02003-fc5a-4d02-fac9-6bc57ec29cf4"
      },
      "source": [
        "dota_p_combined_seed_val = 59\n",
        "#Training phase of Dota 2 and player combined messages model\n",
        "dota_p_combined_loss_values = train_model(dota_p_combined_model, dota_p_combined_seed_val, dota_p_combined_epochs, dota_p_combined_optimizer, dota_p_combined_scheduler, dota_p_combined_train_dataloader,dota_p_combined_validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    496.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    496.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    496.    Elapsed: 0:00:19.\n",
            "  Batch   160  of    496.    Elapsed: 0:00:26.\n",
            "  Batch   200  of    496.    Elapsed: 0:00:32.\n",
            "  Batch   240  of    496.    Elapsed: 0:00:39.\n",
            "  Batch   280  of    496.    Elapsed: 0:00:45.\n",
            "  Batch   320  of    496.    Elapsed: 0:00:52.\n",
            "  Batch   360  of    496.    Elapsed: 0:00:58.\n",
            "  Batch   400  of    496.    Elapsed: 0:01:05.\n",
            "  Batch   440  of    496.    Elapsed: 0:01:11.\n",
            "  Batch   480  of    496.    Elapsed: 0:01:18.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epoch took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    496.    Elapsed: 0:00:06.\n",
            "  Batch    80  of    496.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    496.    Elapsed: 0:00:19.\n",
            "  Batch   160  of    496.    Elapsed: 0:00:26.\n",
            "  Batch   200  of    496.    Elapsed: 0:00:32.\n",
            "  Batch   240  of    496.    Elapsed: 0:00:38.\n",
            "  Batch   280  of    496.    Elapsed: 0:00:45.\n",
            "  Batch   320  of    496.    Elapsed: 0:00:51.\n",
            "  Batch   360  of    496.    Elapsed: 0:00:58.\n",
            "  Batch   400  of    496.    Elapsed: 0:01:04.\n",
            "  Batch   440  of    496.    Elapsed: 0:01:11.\n",
            "  Batch   480  of    496.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epoch took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    496.    Elapsed: 0:00:06.\n",
            "  Batch    80  of    496.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    496.    Elapsed: 0:00:19.\n",
            "  Batch   160  of    496.    Elapsed: 0:00:26.\n",
            "  Batch   200  of    496.    Elapsed: 0:00:32.\n",
            "  Batch   240  of    496.    Elapsed: 0:00:38.\n",
            "  Batch   280  of    496.    Elapsed: 0:00:45.\n",
            "  Batch   320  of    496.    Elapsed: 0:00:51.\n",
            "  Batch   360  of    496.    Elapsed: 0:00:57.\n",
            "  Batch   400  of    496.    Elapsed: 0:01:04.\n",
            "  Batch   440  of    496.    Elapsed: 0:01:10.\n",
            "  Batch   480  of    496.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epoch took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    496.    Elapsed: 0:00:06.\n",
            "  Batch    80  of    496.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    496.    Elapsed: 0:00:19.\n",
            "  Batch   160  of    496.    Elapsed: 0:00:25.\n",
            "  Batch   200  of    496.    Elapsed: 0:00:32.\n",
            "  Batch   240  of    496.    Elapsed: 0:00:38.\n",
            "  Batch   280  of    496.    Elapsed: 0:00:45.\n",
            "  Batch   320  of    496.    Elapsed: 0:00:51.\n",
            "  Batch   360  of    496.    Elapsed: 0:00:57.\n",
            "  Batch   400  of    496.    Elapsed: 0:01:04.\n",
            "  Batch   440  of    496.    Elapsed: 0:01:10.\n",
            "  Batch   480  of    496.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3aiXvLQtH54"
      },
      "source": [
        "# **Test BERT with Dota 2 and player combined messages on Dota 2 test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T67rgOens7Oq"
      },
      "source": [
        "# Predictions for Dota 2 test set with OLID and Dota 2 model\n",
        "dota_p_combined_predictions, dota_p_combined_true_labels = prediction_model(dota_p_combined_model, dota_prediction_dataloader,dota_prediction_inputs)\n",
        "\n",
        "dota_p_combined_flat_true_labels, dota_p_combined_flat_predictions = flatten_labels(dota_p_combined_true_labels, dota_p_combined_predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRwSSMtxtBzu"
      },
      "source": [
        "#Results...\n",
        "\n",
        "# Calculate the MCC\n",
        "dota_p_combined_mcc = calc_matt_corrcoef(dota_p_combined_flat_true_labels, dota_p_combined_flat_predictions)\n",
        "\n",
        "# Calculate the precision and recall\n",
        "precision_recall(dota_p_combined_flat_true_labels,dota_p_combined_flat_predictions)\n",
        "\n",
        "# Calculate the F1 score, binary and macro\n",
        "dota_p_combined_f1 = calc_f1(dota_p_combined_flat_true_labels,dota_p_combined_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJOJkHqYtDO7"
      },
      "source": [
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(dota_p_combined_flat_true_labels,dota_p_combined_flat_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB4ps7JGtE4K"
      },
      "source": [
        "# TP, TN, FP, FN for Dota 2 model predicting Dota 2 test set\n",
        "dota_p_combined_tp, dota_p_combined_tn, dota_p_combined_fp, dota_p_combined_fn = predict_cases(dota_p_combined_flat_true_labels,dota_p_combined_flat_predictions, dota_test_sentences)\n",
        "\n",
        "tp_exp = pd.DataFrame(data = dota_p_combined_tp,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "tp_exp.to_csv('dota_p_combined_tp.csv',index = False)\n",
        "\n",
        "tn_exp = pd.DataFrame(data = dota_p_combined_tn,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "tn_exp.to_csv('dota_p_combined_tn.csv',index = False)\n",
        "\n",
        "fp_exp = pd.DataFrame(data = dota_p_combined_fp,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "fp_exp.to_csv('dota_p_combined_fp.csv',index = False)\n",
        "\n",
        "fn_exp = pd.DataFrame(data = dota_p_combined_fn,columns=[\"message\",\"predicted label\",\"true label\"])\n",
        "fn_exp.to_csv('dota_p_combined_fn.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}